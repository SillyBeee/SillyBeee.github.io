[{"id":"662b057187cfe7607b2d798de545efde","title":"坐标系转换及相机成像原理","content":"\n由于在获取模拟弹道在图像坐标系上的ROI区域获取功能时需要用到坐标系转化的知识,暑假的时候学的不是很明白，遂重温了一遍知识，写下此markdown\n通过一个B站视频 相机模型都没弄懂，怎么搞机器人视觉算法? 快速了解了相机成像和外参矩阵，内参矩阵的大致原理(讲的真的非常好,跟着推一遍就差不多理解了)\n\n\n术语的具体概念\n\n\n\\[ 相机外参(Camera Extrinsics)\\]\n\n是描述相机相对于世界坐标系或其他参考坐标系的位置和方向的参数。外参主要包括两个部分： ####　1.旋转矩阵 (Rotation Matrix) 表示相机的方向，也就是世界坐标系如何通过旋转变换到相机坐标系。 #### 2.平移向量 (Translation Vector) 表示相机的位置，即世界坐标系的原点在相机坐标系中的位置。外参的作用是将世界坐标系的点转换到相机坐标系，通过以下公式实现： \\[\nP_{\\text{camera}} = R \\cdot P_{\\text{world}} + T \n\\] 其中: - $ P_{} $ :点在相机坐标系中的坐标。 - $ P_{} $ :点在世界坐标系中的坐标。 - $ R $: 旋转矩阵，描述相机的方向。 - $ T $: 平移向量，描述相机的位置。\n\n\\[ 内参矩阵（Intrinsic Matrix）\\]\n\n是描述相机内部参数的一个3×3 矩阵，用于将归一化相机坐标系的点映射到图像像素坐标系中的点。它反映了相机的光学特性和传感器设置。 #### 1.内参矩阵的形式 内参矩阵\\(K\\)通常表示为： \\[\nK =\n\\begin{bmatrix}\nf_x &amp; 0   &amp; c_x \\\\\n0   &amp; f_y &amp; c_y \\\\\n0   &amp; 0   &amp; 1\n\\end{bmatrix}\n\\] 其中 - ($ x \\(,\\) y \\():归一化平面上的点坐标（单位化后的相机坐标系，\\)x$ = \\(X_c / Z_c , y = Y_c/Z_c）。\\) - \\((u,v):\\) 图像像素坐标 #### 3. 内参矩阵的含义 - \\(焦距f_x,f_y:\\) - 决定了图像的放大倍数。 - 数值越大，图像越“窄”，也就是视场角（FOV）越小。 - \\(主点c_x,c_y:\\) - 表示传感器坐标系的原点偏移量。 - 如果主点不在图像正中心，则可能是相机安装或制造误差。 &gt; ## 相机投影模型 相机的投影模型可以用以下公式描述： $\n\\[\\begin{bmatrix} u \\\\ v \\\\ 1 \\end{bmatrix}\\]\n=  \n\\[\\begin{bmatrix} f_x &amp; 0 &amp; c_x \\\\ 0 &amp; f_y &amp; c_y \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix}\\]\n\n\\[\\begin{bmatrix} X_c \\\\ Y_c \\\\ Z_c \\end{bmatrix}\\]\n$ #### 2. 公式中的符号解释 - $ (X_c,Y_c,Z_c) :$ 点在\\(相机坐标系\\)下的三维坐标 - $ (u,v)\\(: 点在\\)图像坐标系$（像素坐标系）下的二维坐标。 - \\(f_x,f_y:\\)相机的焦距，分别以像素为单位描述横纵方向上的尺度。通常由相机内参提供。 - \\((c_x,c_y):\\) 主点坐标（Principal Point），表示图像的光轴与图像平面的交点，也由内参提供。 #### 3. 转换过程 根据公式，转换可以分为以下几步：\n\\(（1）归一化设备坐标系（Normalized Device Coordinates）\\) 首先将三维点投影到归一化平面： \\[ x = \\frac{X_c}{Z_c} , y = \\frac{Y_c}{Z_c} \\] 这一步将点从三维相机坐标系投影到二维平面上。 \\((2)映射到图像像素坐标系\\) 通过相机内参矩阵将归一化坐标映射到图像坐标系： \\[ u = f_x \\cdot x + c_x , v = f_y \\cdot y + c_y \\] 得到了点在图像上的像素坐标。 #### 4. 简化公式\n\\[ \\begin{bmatrix} u \\\\ v \\\\ 1 \\end{bmatrix} = \\frac{1}{Z_c} \\cdot K \\cdot \\begin{bmatrix} X_c \\\\ Y_c \\\\ Z_c \\end{bmatrix} \\]\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/***@brief 输入给定pitch角度，弹速，风阻系数，重力系数输出返回图像上的像素点坐标*@param pitch:pitch角度*@param velocity:弹速*@param kof:风阻系数*@param gravity:重力系数**/std::vector&lt;cv::Point2d&gt; ShooterNode::GetROIFromShoot(float pitch, double velocity , double kof , double gravity) &#123;    tf2_ros::Buffer tf_buffer(this-&gt;get_clock());    tf2_ros::TransformListener tf_listener(tf_buffer);    geometry_msgs::msg::TransformStamped transform_stamped;    // 获取shooter坐标系到camera坐标系的变换    try &#123;        transform_stamped = tf_buffer.lookupTransform(            &quot;camera&quot;,            &quot;shooter&quot;,            tf2::TimePointZero        );    &#125; catch (tf2::TransformException &amp;ex) &#123;        RCLCPP_ERROR(rclcpp::get_logger(&quot;shooter_node&quot;), &quot;Transform error: %s&quot;, ex.what());        return;    &#125;     // 开始计算弹道       auto p = tan(pitch/ 180 * M_PI); //pitch的tan值    // 初始化的xyz坐标    double z = 0;     double x = 0;    double y = 0;    // 初始化的线速度    double vx = velocity;    double vy = 0;    // 迭代5次模拟弹道在shooter坐标系下的5个点    std::vector&lt;cv::Point3d&gt; points_pic;  //用于存储弹道在图像坐标系下的5个点    for (int i=0;i&lt;5;i++) &#123;        double t = i*0.1;        double ax = -kof * vx - sin(pitch/ 180 * M_PI);        double ay = gravity * cos(pitch/ 180 * M_PI);        x = x + vx * t + 0.5 * ax * t * t;        y = y + vy * t + 0.5 * ay * t * t;        vx = vx + ax * t;        vy = vy + ay * t;        //计算完毕，将该点转换至camera坐标系下        geometry_msgs::msg::PointStamped point_stamped_shooter;        point_stamped_shooter.point.x = x;        point_stamped_shooter.point.y = y;        point_stamped_shooter.point.z = z;        point_stamped_shooter.header.frame_id = &quot;shooter&quot;;        point_stamped_shooter.header.stamp = this-&gt;get_clock()-&gt;now();        geometry_msgs::msg::PointStamped point_stamped_camera;        tf_buffer.transform(point_stamped_shooter, point_stamped_camera, &quot;camera&quot;);                //将该点转换至图像坐标系下        cv::Mat point_camera = (cv::Mat_&lt;double&gt;(3,1) &lt;&lt; point_stamped_camera.point.x, point_stamped_camera.point.y, point_stamped_camera.point.z);        if (point_camera.at&lt;double&gt;(2,0) = 0) &#123;            RCLCPP_WARN(this-&gt;get_logger(), &quot;相机坐标系下的点的z坐标为0,可能出现了一些错误,已将其赋为0.001&quot;);            point_camera.at&lt;double&gt;(2,0) = 0.001;        &#125;        cv::Mat point_image = camera_matrix_ * point_camera / point_camera.at&lt;double&gt;(2,0);        points_pic.push_back(cv::Point2d(point_image.at&lt;double&gt;(0,0), point_image.at&lt;double&gt;(1,0)));    &#125;    return points_pic;    &#125;\n","slug":"坐标系转换及相机成像原理","date":"2024-12-01T15:06:10.000Z","categories_index":"","tags_index":"C++,相机,坐标系转换","author_index":"SillyBee"},{"id":"d8bc573a4b1b9573bcb50401a437db04","title":"在PVE系统上的NAS与软路由配置","content":"\n","slug":"在PVE系统上的NAS与软路由配置","date":"2024-11-27T16:33:02.000Z","categories_index":"","tags_index":"Proxmox VE,软路由,NAS","author_index":"SillyBee"},{"id":"94a9c222adc80b72684ae498ca16d76a","title":"ubuntu上wine的安装与使用","content":"\nUbuntu：如何安装和使用 Wine 9，轻松运行 Windows 应用 (本文摘自：系统极客)\nWine（即 WineHQ）是一个 Windows 兼容层，允许你在类 Unix 操作系统（如 Linux）上运行 Windows 应用程序，而无需安装双系统或虚拟机。Wine 9.x 是它的最新版本，带来了许多改进，如全新的 WoW64 模式，支持在纯 64 位 Unix 系统上运行 32 位 Windows 应用；增强的 Wayland 支持；以及更好的 ARM64 兼容性。\n此外，Wine 9.x 在图形处理上也有所提升，增加了对 Vulkan 的支持，并更新了 Direct3D、DirectShow 和 DirectMusic，提高了许多应用程序和游戏的性能与兼容性。\n接下来，本文将详细介绍如何通过 WineHQ 官方仓库，在 Ubuntu 上安装、配置和使用 Wine 9。\n\n以下步骤适用于 Ubuntu 20.04、22.04 和 24.04 LTS 版本。\n第 1 步：在 Ubuntu 上安装 Wine 91.1 准备工作1.在安装 Wine 9 之前，先通过「终端」更新系统中的软件包：12sudo apt update  # 更新软件包列表sudo apt upgrade # 升级软件包\n接着，安装必要的依赖工具：1sudo apt install dirmngr ca-certificates curl software-properties-common apt-transport-https\n启用 32 位系统架构支持，增强对游戏和应用程序的兼容性：1sudo dpkg --add-architecture i386\n1.2 添加 WineHQ 官方仓库1.首先，导入 WineHQ 的 GPG 密钥：1curl -s https://dl.winehq.org/wine-builds/winehq.key | sudo gpg --dearmor | sudo tee /usr/share/keyrings/winehq.gpg &gt; /dev/null\n2. 然后，添加 WineHQ 官方仓库：1echo deb [signed-by=/usr/share/keyrings/winehq.gpg] http://dl.winehq.org/wine-builds/ubuntu/ $(lsb_release -cs) main | sudo tee /etc/apt/sources.list.d/winehq.list\n1.3 在 Ubuntu 上安装 Wine 91.首先，在「终端」中更新软件包列表：1sudo apt update\n2.根据你的需求，选择安装不同版本的 Wine 9\n预发布版:功能和稳定性介于原稳定版和开发版之间。1sudo apt install --install-recommends winehq-staging\n开发版: 包含最新功能，但可能不稳定，适合开发者或高级用户。1sudo apt install --install-recommends winehq-devel\n3.安装完成后，检查 Wine 版本以确认安装成功：1wine --version\n第2步:在 Ubuntu 上初始化 Wine 环境2.1配置 Wine 环境1.成功安装 Wine 后，通过以下命令开始设置 Wine 的运行环境，包括安装 wine-mono 组件以支持 .NET 应用：1winecfg\n2.根据提示安装 Mono 及相关依赖。2.2配置 Wine 设置1.配置完成后，会自动弹出「Wine 设置」对话框。你可以选择要模拟的 Windows 版本，默认是「Windows 10」，也可以根据需要自行更改。2.调整「音效」、「显示」等设置，完成后点击「确定」关闭对话框。2.3安装 Winetricks（优化 Wine 使用体验）Winetricks 是一个辅助脚本，可以帮助你轻松安装和管理 Windows 应用程序和库，从而优化 Wine 的使用体验。1.在「终端」中运行以下命令安装 winetricks：sudo apt install winetricks2.安装完成后，可以使用 Winetricks 安装必要的 Windows 组件，例如：一些应用和组件需要配置 32 位应用和中文支持，后续会有介绍。123winetricks vcrun2022 # 安装 Visual C++ 运行库winetricks allfonts corefonts cjkfonts # 安装常用字体，包括中文字体winetricks d3dx9 d3dx10 # 安装 DirectX 提升兼容性和游戏性能\n第 3 步：使用 Wine 运行 Windows 应用程序要运行 Windows 的二进制文件，请右键点击文件并选择「打开方式」，然后选择 Wine。以下是使用 Wine 在 Ubuntu 中安装和运行 Notepad++ 的示例：\n1.下载 Noetpad ++ 安装文件。\n\n\n\n2.右键点击安装文件，选择「打开方式」。\n\n3.选择「Wine Windows Program Loader」，然后点击「打开」。\n\n4.按照安装向导提示完成安装。\n5.安装完成后，即可正常使用 Notepad++\n在 Ubuntu 上管理 Wine 环境管理 Wine 前缀（应用程序环境）Wine 使用前缀（Prefix）来隔离不同的应用程序环境。默认情况下，主前缀路径为~/.wine。如果需要创建一个新的自定义环境，可以使用以下命令：\n1WINEPREFIX=~/.custom_wine_prefix winecfg\n将~/.custom_wine_prefix替换为要使用的目录。执行命令后，会创建一个新的 Wine 环境，并自动打开「Wine 配置」对话框。\n配置 32 位应用支持Wine 默认支持 64 位 Windows 应用。如果要运行 32 位应用程序，可以通过以下命令设置一个新的 32 位环境：\n1WINEARCH=win32 WINEPREFIX=~/.wine32 winecfg\n此命令会创建一个专门用于 32 位应用程序的 Wine 前缀。\n配置中文支持要创建一个支持中文的 Wine 前缀，请带上LC_ALL=zh_CN.UTF-8参数：\n1WINEPREFIX=/home/billyfu/wine_prefix LC_ALL=zh_CN.UTF-8 winecfg\n浏览 Wine 应用程序数据库Wine 应用程序数据库 (AppDB) 提供了各种应用程序的兼容性信息和优化配置建议。你可以访问 Wine AppDB 了解更多详细信息，以及其他用户分享的经验。\n从 Ubuntu 中移除 Wine如果不再需要 Wine，可以按以下步骤从 Ubuntu 中卸载：\n1卸载 Wine：12sudo apt remove winehq-staging # 卸载预发布版sudo apt remove winehq-devel # 卸载开发版\n2移除 WineHQ 仓库：1sudo rm /etc/apt/sources.list.d/winehq.list\n3删除 GPG 密钥：1sudo rm /usr/share/keyrings/winehq.gpg\n\n\n\n","slug":"ubuntu上wine的安装与使用","date":"2024-11-19T15:17:13.000Z","categories_index":"","tags_index":"wine,ubuntu","author_index":"SillyBee"},{"id":"cd3c61450f9ac60e6bfe52ccccb004e4","title":"Ubuntu如何使用Zerotier实现远程串流","content":"本文实现使用平板远程串流电脑环境要求:1.sunshine(ubuntu上)                   \n2.moonlight与zerotier one(平板或手机上)\n3.zerotier (ubuntu上)\n在ubuntu上安装zerotier1.运行一下代码即可1$ curl -s https://install.zerotier.com | sudo bash\n可以设置让zerotier开机自启动12$ sudo systemctl start zerotier-one.service$ sudo systemctl enable zerotier-one.servicemoonlight和sunshine的安装就不多赘述了，不会的可以自己搜索，zerotier one 可以在google商店内下载\n使用流程 1.在zerotier官网 ZeroTier Central  注册并进入\n2.创建自己的网络，点击Create A Network后会得到一个具有随机id与名称的虚拟网络\n3.众所周知，sunshine&amp;moonlight可以实现局域网的串流，而zerotier发挥的作用就是将在公网内的不同设备拉入一个虚拟的局域网（有点类似于小时候的游侠对战平台，实现的效果差不多）\n不同平台加入zerotier网络的方法：\nUbuntu：打开终端输入1$ sudo zerotier-cli join &lt;your id&gt;\n　移动端：在应用商店下载zerotier后点击右上角的ADD　NETWORK后输入网络id即可\n4.进入第一部的ZeroTier Central点击网络进入网络管理页面，在members栏目下点击每一个设备旁的edit按钮，勾选anthorized进行授权，授权后设备才可以成功接入虚拟局域网\n5.所需设备接入zerotier后即可用正常的sunshine&amp;moonlight流程进行串流\nEND：发现每次电脑加入zerotier网络好麻烦，所以写了个脚本\n可以新建文本文件并添加可执行权限，文本内容为123#!/bin/bash#打开新的终端窗口并执行命令gnome-terminal -- bash -c &quot;sudo zerotier-cli join 你的网络id; exec bash&quot;这样每次运行这个脚本就可以加入网络了\n​\n","slug":"ubuntu如何使用zerotier实现远程串流","date":"2024-11-15T15:16:22.000Z","categories_index":"","tags_index":"ubuntu,zerotier,moonlight,sunshine","author_index":"SillyBee"},{"id":"ebaa4a924ab8e8b5b45edc965a35412f","title":"基于OpenCV的相机软防抖","content":"1.识别抖动寻找帧之间的移动，这是算法中最关键的部分。我们将遍历所有的帧，并找到当前帧和前一帧之间的移动。欧几里得运动模型要求我们知道两个坐标系中两个点的运动。但是在实际应用中，找到50-100个点的运动，然后用它们来稳健地估计运动模型。\n特征跟踪首先需要识别出易跟踪的特征，光滑的区域不利于跟踪，而有很多角的纹理区域则比较好。OpenCV有一个快速的特征检测器goodFeaturesToTrack，可以检测最适合跟踪的特性。\n我们在前一帧中找到好的特征，就可以使用Lucas-Kanade光流算法在下一帧中跟踪它们。它是利用OpenCV中的calcOpticalFlowPyrLK函数实现的。\n接着估计运动，我们已经找到了特征在当前帧中的位置，并且我们已经知道了特征在前一帧中的位置。所以我们可以使用这两组点来找到映射前一个坐标系到当前坐标系的刚性（欧几里德）变换。这是使用函数estimateRigidTransform完成的。12345678910111213141516171819202122232425262728293031# 检测前一帧的特征点prev_pts = cv2.goodFeaturesToTrack(prev_gray,                                   maxCorners=200,                                   qualityLevel=0.01,                                   minDistance=30,                                   blockSize=3)# 读下一帧success, curr = cap.read()if not success:    break# 转换为灰度图curr_gray = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)# 计算光流(即轨迹特征点)curr_pts, status, err = cv2.calcOpticalFlowPyrLK(    prev_gray, curr_gray, prev_pts, None)# 检查完整性assert prev_pts.shape == curr_pts.shape# 只过滤有效点idx = np.where(status == 1)[0]prev_pts = prev_pts[idx]curr_pts = curr_pts[idx]# 找到变换矩阵# 只适用于OpenCV-3或更少的版本吗# m = cv2.estimateRigidTransform(prev_pts, curr_pts, fullAffine=False)m, inlier = cv2.estimateAffine2D(prev_pts, curr_pts, )\n2.计算帧间的平滑运动在前面的步骤中，我们估计帧之间的运动并将它们存储在一个数组中。我们现在需要通过叠加上一步估计的微分运动来找到运动轨迹。\n轨迹计算，在这一步，我们将增加运动之间的帧来计算轨迹。我们的最终目标是平滑这条轨迹，可以很容易地使用numpy中的cumsum(累计和)来实现。\n计算平滑轨迹，我们计算了运动轨迹。所以我们有三条曲线来显示运动(x, y，和角度)如何随时间变化。\n平滑任何曲线最简单的方法是使用移动平均滤波器（moving average filter）。顾名思义，移动平均过滤器将函数在某一点上的值替换为由窗口定义的其相邻函数的平均值。123456789101112131415161718192021def movingAverage(curve, radius):    window_size = 2 * radius + 1    # 定义过滤器    f = np.ones(window_size) / window_size    # 为边界添加填充    curve_pad = np.lib.pad(curve, (radius, radius), &#x27;edge&#x27;)    # 应用卷积    curve_smoothed = np.convolve(curve_pad, f, mode=&#x27;same&#x27;)    # 删除填充    curve_smoothed = curve_smoothed[radius:-radius]    # 返回平滑曲线    return curve_smootheddef smooth(trajectory):    smoothed_trajectory = np.copy(trajectory)    # 过滤x, y和角度曲线    for i in range(3):        smoothed_trajectory[:, i] = movingAverage(            trajectory[:, i], radius=SMOOTHING_RADIUS)    return smoothed_trajectory计算平滑变换到目前为止，我们已经得到了一个平滑的轨迹。在这一步，我们将使用平滑的轨迹来获得平滑的变换，可以应用到视频的帧来稳定它。\n这是通过找到平滑轨迹和原始轨迹之间的差异，并将这些差异加回到原始的变换中来完成的。1234567891011# 使用累积变换和计算轨迹trajectory = np.cumsum(transforms, axis=0)# 创建变量来存储平滑的轨迹smoothed_trajectory = smooth(trajectory)# 计算smoothed_trajectory与trajectory的差值difference = smoothed_trajectory - trajectory# 计算更新的转换数组transforms_smooth = transforms + difference\n3.将平滑的摄像机运动应用到帧中现在我们所需要做的就是循环帧并应用我们刚刚计算的变换。如果我们有一个指定为(x, y, θ),的运动，对应的变换矩阵是：\n\nT = \\begin{bmatrix}\n\\cos\\theta & -\\sin\\theta & x \\\\\n\\sin\\theta & \\cos\\theta & y \\\\\n\\end{bmatrix}1234567891011121314151617181920212223# 从新的转换数组中提取转换dx = transforms_smooth[i, 0]dy = transforms_smooth[i, 1]da = transforms_smooth[i, 2]# 根据新的值重构变换矩阵m = np.zeros((2, 3), np.float32)m[0, 0] = np.cos(da)m[0, 1] = -np.sin(da)m[1, 0] = np.sin(da)m[1, 1] = np.cos(da)m[0, 2] = dxm[1, 2] = dy# 应用仿射包装到给定的框架frame_stabilized = cv2.warpAffine(frame, m, (w, h))# Fix border artifactsframe_stabilized = fixBorder(frame_stabilized)# 将框架写入文件frame_out = frame_stabilizedout.write(frame_out)\n修复边界伪影当我们稳定一个视频，我们可能会看到一些黑色的边界伪影。这是意料之中的，因为为了稳定视频，帧可能不得不缩小大小。我们可以通过将视频的中心缩小一小部分(例如4%)来缓解这个问题。\n下面的fixBorder函数显示了实现。我们使用getRotationMatrix2D，因为它在不移动图像中心的情况下缩放和旋转图像。我们所需要做的就是调用这个函数时，旋转为0，缩放为1.04(也就是提升4%)。\n123456def fixBorder(frame):    s = frame.shape    # 在不移动中心的情况下，将图像缩放4%    T = cv2.getRotationMatrix2D((s[1] / 2, s[0] / 2), 0, 1.04)    frame = cv2.warpAffine(frame, T, (s[1], s[0]))    return frame\n","slug":"基于OpenCV的相机软防抖","date":"2024-11-15T04:40:49.000Z","categories_index":"","tags_index":"C++,OpenCV,Python,光流法,特征点匹配","author_index":"SillyBee"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post1$ hexo new &quot;My New Post&quot;\nMore info: Writing\nRun server1$ hexo server\nMore info: Server\nGenerate static files1$ hexo generate\nMore info: Generating\nDeploy to remote sites1$ hexo deploy\nMore info: Deployment\n","slug":"hello-world","date":"2024-11-13T08:10:41.948Z","categories_index":"","tags_index":"","author_index":"SillyBee"}]