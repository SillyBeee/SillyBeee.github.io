[{"id":"cd3c61450f9ac60e6bfe52ccccb004e4","title":"Ubuntu如何使用Zerotier实现远程串流","content":"本文实现使用平板远程串流电脑环境要求:1.sunshine(ubuntu上)                   \n2.moonlight与zerotier one(平板或手机上)\n3.zerotier (ubuntu上)\n在ubuntu上安装zerotier1.运行一下代码即可\n1$ curl -s https://install.zerotier.com | sudo bash\n\n可以设置让zerotier开机自启动\n12$ sudo systemctl start zerotier-one.service$ sudo systemctl enable zerotier-one.service\nmoonlight和sunshine的安装就不多赘述了，不会的可以自己搜索，zerotier one 可以在google商店内下载\n使用流程 1.在zerotier官网 ZeroTier Central  注册并进入\n2.创建自己的网络，点击Create A Network后会得到一个具有随机id与名称的虚拟网络\n3.众所周知，sunshine&amp;moonlight可以实现局域网的串流，而zerotier发挥的作用就是将在公网内的不同设备拉入一个虚拟的局域网（有点类似于小时候的游侠对战平台，实现的效果差不多）\n不同平台加入zerotier网络的方法：\nUbuntu：打开终端输入1$ sudo zerotier-cli join &lt;your id&gt;\n移动端：在应用商店下载zerotier后点击右上角的ADD　NETWORK后输入网络id即可\n4.进入第一部的ZeroTier Central点击网络进入网络管理页面，在members栏目下点击每一个设备旁的edit按钮，勾选anthorized进行授权，授权后设备才可以成功接入虚拟局域网\n5.所需设备接入zerotier后即可用正常的sunshine&amp;moonlight流程进行串流\nEND：发现每次电脑加入zerotier网络好麻烦，所以写了个脚本\n可以新建文本文件并添加可执行权限，文本内容为\n123#!/bin/bash#打开新的终端窗口并执行命令gnome-terminal -- bash -c &quot;sudo zerotier-cli join 你的网络id; exec bash&quot;\n这样每次运行这个脚本就可以加入网络了\n​\n","slug":"ubuntu如何使用zerotier实现远程串流","date":"2024-11-15T15:16:22.000Z","categories_index":"","tags_index":"zerotier,moonlight,sunshine,ubuntu","author_index":"SillyBee"},{"id":"ebaa4a924ab8e8b5b45edc965a35412f","title":"基于OpenCV的相机软防抖","content":"1.识别抖动寻找帧之间的移动，这是算法中最关键的部分。我们将遍历所有的帧，并找到当前帧和前一帧之间的移动。欧几里得运动模型要求我们知道两个坐标系中两个点的运动。但是在实际应用中，找到50-100个点的运动，然后用它们来稳健地估计运动模型。\n特征跟踪首先需要识别出易跟踪的特征，光滑的区域不利于跟踪，而有很多角的纹理区域则比较好。OpenCV有一个快速的特征检测器goodFeaturesToTrack，可以检测最适合跟踪的特性。\n我们在前一帧中找到好的特征，就可以使用Lucas-Kanade光流算法在下一帧中跟踪它们。它是利用OpenCV中的calcOpticalFlowPyrLK函数实现的。\n接着估计运动，我们已经找到了特征在当前帧中的位置，并且我们已经知道了特征在前一帧中的位置。所以我们可以使用这两组点来找到映射前一个坐标系到当前坐标系的刚性（欧几里德）变换。这是使用函数estimateRigidTransform完成的。\n12345678910111213141516171819202122232425262728293031# 检测前一帧的特征点prev_pts = cv2.goodFeaturesToTrack(prev_gray,                                   maxCorners=200,                                   qualityLevel=0.01,                                   minDistance=30,                                   blockSize=3)# 读下一帧success, curr = cap.read()if not success:    break# 转换为灰度图curr_gray = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)# 计算光流(即轨迹特征点)curr_pts, status, err = cv2.calcOpticalFlowPyrLK(    prev_gray, curr_gray, prev_pts, None)# 检查完整性assert prev_pts.shape == curr_pts.shape# 只过滤有效点idx = np.where(status == 1)[0]prev_pts = prev_pts[idx]curr_pts = curr_pts[idx]# 找到变换矩阵# 只适用于OpenCV-3或更少的版本吗# m = cv2.estimateRigidTransform(prev_pts, curr_pts, fullAffine=False)m, inlier = cv2.estimateAffine2D(prev_pts, curr_pts, )\n2.计算帧间的平滑运动在前面的步骤中，我们估计帧之间的运动并将它们存储在一个数组中。我们现在需要通过叠加上一步估计的微分运动来找到运动轨迹。\n轨迹计算，在这一步，我们将增加运动之间的帧来计算轨迹。我们的最终目标是平滑这条轨迹，可以很容易地使用numpy中的cumsum(累计和)来实现。\n计算平滑轨迹，我们计算了运动轨迹。所以我们有三条曲线来显示运动(x, y，和角度)如何随时间变化。\n平滑任何曲线最简单的方法是使用移动平均滤波器（moving average filter）。顾名思义，移动平均过滤器将函数在某一点上的值替换为由窗口定义的其相邻函数的平均值。\n123456789101112131415161718192021def movingAverage(curve, radius):    window_size = 2 * radius + 1    # 定义过滤器    f = np.ones(window_size) / window_size    # 为边界添加填充    curve_pad = np.lib.pad(curve, (radius, radius), &#x27;edge&#x27;)    # 应用卷积    curve_smoothed = np.convolve(curve_pad, f, mode=&#x27;same&#x27;)    # 删除填充    curve_smoothed = curve_smoothed[radius:-radius]    # 返回平滑曲线    return curve_smootheddef smooth(trajectory):    smoothed_trajectory = np.copy(trajectory)    # 过滤x, y和角度曲线    for i in range(3):        smoothed_trajectory[:, i] = movingAverage(            trajectory[:, i], radius=SMOOTHING_RADIUS)    return smoothed_trajectory\n计算平滑变换到目前为止，我们已经得到了一个平滑的轨迹。在这一步，我们将使用平滑的轨迹来获得平滑的变换，可以应用到视频的帧来稳定它。\n这是通过找到平滑轨迹和原始轨迹之间的差异，并将这些差异加回到原始的变换中来完成的。\n1234567891011# 使用累积变换和计算轨迹trajectory = np.cumsum(transforms, axis=0)# 创建变量来存储平滑的轨迹smoothed_trajectory = smooth(trajectory)# 计算smoothed_trajectory与trajectory的差值difference = smoothed_trajectory - trajectory# 计算更新的转换数组transforms_smooth = transforms + difference\n3.将平滑的摄像机运动应用到帧中现在我们所需要做的就是循环帧并应用我们刚刚计算的变换。如果我们有一个指定为(x, y, θ),的运动，对应的变换矩阵是：\n$$T &#x3D; \\begin{bmatrix}\\cos\\theta &amp; -\\sin\\theta &amp; x \\\\sin\\theta &amp; \\cos\\theta &amp; y \\\\end{bmatrix}$$\n1234567891011121314151617181920212223# 从新的转换数组中提取转换dx = transforms_smooth[i, 0]dy = transforms_smooth[i, 1]da = transforms_smooth[i, 2]# 根据新的值重构变换矩阵m = np.zeros((2, 3), np.float32)m[0, 0] = np.cos(da)m[0, 1] = -np.sin(da)m[1, 0] = np.sin(da)m[1, 1] = np.cos(da)m[0, 2] = dxm[1, 2] = dy# 应用仿射包装到给定的框架frame_stabilized = cv2.warpAffine(frame, m, (w, h))# Fix border artifactsframe_stabilized = fixBorder(frame_stabilized)# 将框架写入文件frame_out = frame_stabilizedout.write(frame_out)\n修复边界伪影当我们稳定一个视频，我们可能会看到一些黑色的边界伪影。这是意料之中的，因为为了稳定视频，帧可能不得不缩小大小。我们可以通过将视频的中心缩小一小部分(例如4%)来缓解这个问题。\n下面的fixBorder函数显示了实现。我们使用getRotationMatrix2D，因为它在不移动图像中心的情况下缩放和旋转图像。我们所需要做的就是调用这个函数时，旋转为0，缩放为1.04(也就是提升4%)。\n123456def fixBorder(frame):    s = frame.shape    # 在不移动中心的情况下，将图像缩放4%    T = cv2.getRotationMatrix2D((s[1] / 2, s[0] / 2), 0, 1.04)    frame = cv2.warpAffine(frame, T, (s[1], s[0]))    return frame\n","slug":"基于OpenCV的相机软防抖","date":"2024-11-15T04:40:49.000Z","categories_index":"","tags_index":"OpenCV,C++,Python,光流法,特征点匹配","author_index":"SillyBee"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post1$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server1$ hexo server\n\nMore info: Server\nGenerate static files1$ hexo generate\n\nMore info: Generating\nDeploy to remote sites1$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2024-11-13T08:10:41.948Z","categories_index":"","tags_index":"","author_index":"SillyBee"}]